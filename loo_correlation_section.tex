\subsection{Leave-One-Out Cross-Validation Correlation Structure}

A critical challenge in our framework is that the $N$ leave-one-out (LOO) predictions are not independent. The training sets for different folds overlap substantially---folds $i$ and $j$ using training sets $\mathcal{D}_{-i}$ and $\mathcal{D}_{-j}$ differ by only two examples out of $N-1$. Because each fold's threshold is computed from nearly identical data, the resulting predictions exhibit strong positive correlation. This correlation structure invalidates standard assumptions of independence typically used in statistical inference and requires specialized correction methods when computing diagnostic bounds.

To account for this dependency, we employ an empirical variance inflation factor $\phi$ that quantifies the degree of correlation in the LOO predictions. Let $x_i \in \{0,1\}$ for $i=1,\ldots,n$ denote the binary LOO predictions, and let $\hat{p} = \frac{1}{n}\sum_{i=1}^n x_i$ be their empirical mean. The sample variance is computed with Bessel's correction as $\mathrm{Var}_{\text{empirical}} = \frac{1}{n-1}\sum_{i=1}^n (x_i - \hat{p})^2$. Under the assumption of independence, the expected variance would be $\mathrm{Var}_{\text{IID}} = \hat{p}(1-\hat{p})$. The inflation factor quantifies how much the empirical variance exceeds this independence baseline:
\begin{equation}
\phi = \frac{\mathrm{Var}_{\text{empirical}}}{\mathrm{Var}_{\text{IID}}} \times \frac{n}{n-1}.
\end{equation}
The factor $n/(n-1)$ provides a finite-sample adjustment that accounts for the relationship between the sample variance estimator and the population variance. This ensures that the inflation factor properly reflects the correlation structure even in small samples. For large $n$, the ratio $\mathrm{Var}_{\text{empirical}}/\mathrm{Var}_{\text{IID}}$ approaches the theoretical inflation value of approximately 2.0, while the correction factor $n/(n-1)$ approaches 1.

For large $n$, this ratio approaches the theoretical value of $\phi \approx 2.0$, which reflects the expected variance inflation from LOO-CV's overlapping training sets. However, for small samples ($n = 20$--$40$), the actual inflation can vary depending on the model and data structure. To ensure robustness against outliers and numerical instability, we clip the estimated factor to the range $[1.0, 6.0]$. This empirically-estimated inflation factor is then incorporated into our uncertainty quantification methods to provide properly calibrated bounds that account for the correlation structure inherent in LOO-CV.
