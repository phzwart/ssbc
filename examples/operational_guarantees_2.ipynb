{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6baac-5c4d-46d7-b584-90dafb1284f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ssbc import generate_rigorous_pac_report\n",
    "import ssbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab08a51-6f48-4744-b5e4-3dc0ad3c0f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_class1 = 0.30\n",
    "beta_params_class0 = (2, 5)\n",
    "beta_params_class1 = (5, 2)\n",
    "\n",
    "alpha_0 = 0.10\n",
    "delta_0 = 0.10\n",
    "alpha_1 = 0.10\n",
    "delta_1 = 0.10\n",
    "\n",
    "N_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5bfa44-f870-4d56-b256-918254c5e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = ssbc.BinaryClassifierSimulator(\n",
    "    p_class1=p_class1, beta_params_class0=beta_params_class0, beta_params_class1=beta_params_class1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd781237-6c90-4ecc-8817-0ad0b0cb7f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, probs = sim.generate(N_samples)\n",
    "class_data = ssbc.split_by_class(labels=labels, probs=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7261fb9-e2fe-45aa-8a83-9a74966b4cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(class_data[0][\"probs\"][:, 1], bins=np.linspace(0, 1, 50), alpha=0.75)\n",
    "plt.hist(class_data[1][\"probs\"][:, 1], bins=np.linspace(0, 1, 50), alpha=0.75)\n",
    "plt.legend([\"Background\", \"Foreground\"])\n",
    "plt.ylabel(\"P(Foregournd)\")\n",
    "plt.xlabel(\"Pr\")\n",
    "plt.savefig(\"tst.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf6ef5-2f77-4ec1-a1d8-2d0353fd873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate report (now using SIMPLIFIED bounds)\n",
    "report = generate_rigorous_pac_report(\n",
    "    labels=labels,\n",
    "    probs=probs,\n",
    "    alpha_target=0.10,\n",
    "    delta=0.10,\n",
    "    test_size=N_samples,\n",
    "    ci_level=0.95,\n",
    "    use_union_bound=False,\n",
    "    prediction_method=\"all\",\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    "    loo_inflation_factor=2.5,\n",
    "    use_loo_correction=True\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be629d45-8218-48ef-b1c8-f0b246959267",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = ssbc.validate_pac_bounds(\n",
    "    report=report,\n",
    "    simulator=sim,\n",
    "    test_size=N_samples,      # Size of each test set\n",
    "    n_trials=100000,       # Number of independent trials (increase for better stats)\n",
    "    seed=42,             # For reproducibility\n",
    "    verbose=True,\n",
    "    n_jobs=-1,           # Use all CPU cores\n",
    ")\n",
    "\n",
    "ssbc.print_validation_results(validation)\n",
    "\n",
    "\n",
    "from ssbc import plot_validation_bounds\n",
    "\n",
    "# Simple usage\n",
    "plot_validation_bounds(validation, metric=\"singleton\")\n",
    "\n",
    "# Customize\n",
    "plot_validation_bounds(\n",
    "    validation, \n",
    "    metric=\"singleton\", \n",
    "    show_detail=True,\n",
    "    bins=100,\n",
    "    return_figs=False\n",
    ")\n",
    "\n",
    "# Or get figures for saving/customization\n",
    "fig_main, fig_detail = plot_validation_bounds(\n",
    "    validation, \n",
    "    metric=\"singleton\", \n",
    "    return_figs=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631bd31-4ef2-4861-be9a-d97338d93a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ssbc.validate_prediction_interval_calibration(\n",
    "    simulator=sim,\n",
    "    n_calibration=N_samples,        # Size of each calibration dataset\n",
    "    BigN=50,                  # Number of different calibrations to test\n",
    "    n_trials=5000,             # Test sets per calibration\n",
    "    test_size=N_samples,\n",
    "    ci_level=0.95,\n",
    "    prediction_method=\"all\",  # Compare all methods\n",
    "    use_loo_correction=True,\n",
    "    loo_inflation_factor=2.0,\n",
    "    verbose=False,            # Minimal printouts\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c9a16-5acc-4a8b-bc59-67adaf7e1f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "ssbc.print_calibration_validation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e0288-c86b-4920-8885-d4bf2126ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssbc import validate_prediction_interval_calibration, get_calibration_bounds_dataframe\n",
    "\n",
    "# Run meta-validation\n",
    "\n",
    "\n",
    "# Extract DataFrame\n",
    "df = get_calibration_bounds_dataframe(results)\n",
    "\n",
    "# Filter specific datasets\n",
    "df_single = df[(df['scope'] == 'class_0') & (df['metric'] == 'singleton')]\n",
    "\n",
    "# Plot lower bounds comparison\n",
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Lower quantiles\n",
    "ax1.scatter(df_single['analytical_lower'], df_single['observed_q05'], label='Analytical', alpha=0.6)\n",
    "ax1.scatter(df_single['exact_lower'], df_single['observed_q05'], label='Exact', alpha=0.6)\n",
    "ax1.plot([0.90, 1], [0.90, 1], 'k--', label='Perfect')\n",
    "ax1.set_xlabel('Predicted Lower Bound')\n",
    "ax1.set_ylabel('Observed 5th Percentile')\n",
    "ax1.legend()\n",
    "\n",
    "# Upper quantiles  \n",
    "ax2.scatter(df_single['analytical_upper'], df_single['observed_q95'], label='Analytical', alpha=0.6)\n",
    "ax2.scatter(df_single['exact_upper'], df_single['observed_q95'], label='Exact', alpha=0.6)\n",
    "ax2.plot([0.9, 1], [0.90, 1], 'k--', label='Perfect')\n",
    "ax2.set_xlabel('Predicted Upper Bound')\n",
    "ax2.set_ylabel('Observed 95th Percentile')\n",
    "\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569f327-6202-4bd4-ab4e-6f12d9c1b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssbc import (\n",
    "    validate_prediction_interval_calibration,\n",
    "    get_calibration_bounds_dataframe,\n",
    "    plot_calibration_excess,\n",
    ")\n",
    "# Plot excess for singleton marginal\n",
    "df_single = df[(df['scope'] == 'marginal') & (df['metric'] == 'singleton')]\n",
    "plot_calibration_excess(df_single, scope='marginal', metric='singleton')\n",
    "\n",
    "# Or directly filter in the function\n",
    "plot_calibration_excess(df, scope='marginal', metric='singleton', methods=['analytical', 'exact'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e284ed4-a33b-4558-8a8c-87ddd91ae380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f05e911-6c05-4c44-bf14-19740547dad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
