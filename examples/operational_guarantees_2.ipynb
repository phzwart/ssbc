{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f6baac-5c4d-46d7-b584-90dafb1284f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ssbc import generate_rigorous_pac_report\n",
    "import ssbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab08a51-6f48-4744-b5e4-3dc0ad3c0f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_class1 = 0.10\n",
    "beta_params_class0 = (2, 7)\n",
    "beta_params_class1 = (4, 2)\n",
    "\n",
    "alpha_0 = 0.10\n",
    "delta_0 = 0.10\n",
    "alpha_1 = 0.10\n",
    "delta_1 = 0.10\n",
    "\n",
    "N_samples = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf5bfa44-f870-4d56-b256-918254c5e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = ssbc.BinaryClassifierSimulator(\n",
    "    p_class1=p_class1, beta_params_class0=beta_params_class0, beta_params_class1=beta_params_class1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd781237-6c90-4ecc-8817-0ad0b0cb7f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7651113059565858\n",
      "0.6264166114587717\n",
      "60\n",
      "440\n"
     ]
    }
   ],
   "source": [
    "labels, probs = sim.generate(N_samples)\n",
    "class_data = ssbc.split_by_class(labels=labels, probs=probs)\n",
    "print(np.mean(probs[labels==0, 0]))\n",
    "print(np.mean(probs[labels==1, 1]))\n",
    "print(np.sum(labels==1))\n",
    "print(np.sum(labels==0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7261fb9-e2fe-45aa-8a83-9a74966b4cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(class_data[0][\"probs\"][:, 1], bins=np.linspace(0, 1, 50), alpha=0.75)\n",
    "plt.hist(class_data[1][\"probs\"][:, 1], bins=np.linspace(0, 1, 50), alpha=0.75)\n",
    "plt.legend([\"Class 0\", \"Class 1\"])\n",
    "plt.ylabel(\"P(Class 1)\")\n",
    "plt.xlabel(\"Pr\")\n",
    "plt.savefig(\"tst-2-7_7_2.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93cf6ef5-2f77-4ec1-a1d8-2d0353fd873a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OPERATIONAL PAC-CONTROLLED CONFORMAL PREDICTION REPORT\n",
      "================================================================================\n",
      "\n",
      "Parameters:\n",
      "  Test size: 500\n",
      "  CI level: 95% (Clopper-Pearson)\n",
      "  PAC guarantee levels:\n",
      "    Class 0: δ = 0.10 (90% confidence)\n",
      "    Class 1: δ = 0.10 (90% confidence)\n",
      "    Union bound: not applied (metrics validated independently)\n",
      "    Class guarantees: validated separately\n",
      "\n",
      "================================================================================\n",
      "CLASS 0 (Conditioned on True Label = 0)\n",
      "================================================================================\n",
      "  Calibration size: n = 440\n",
      "  Target miscoverage: α = 0.100\n",
      "  SSBC-corrected α:   α' = 0.0816\n",
      "  PAC risk:           δ = 0.100\n",
      "  Conformal threshold: 0.4552\n",
      "\n",
      "  Calibration summary (n = 440)\n",
      "     Empirical rates on calibration data. Intervals are 95% Clopper-Pearson.\n",
      "     These do not include PAC guarantees.\n",
      "     Abstentions:              19 /  440  =  4.32%   95% CI: [0.026, 0.067]\n",
      "     Singletons:            421 /  440  = 95.68%   95% CI: [0.933, 0.974]\n",
      "       Correct:             405 /  440  = 92.05%   95% CI: [0.891, 0.944]\n",
      "       Incorrect:             16 /  440  =  3.64%   95% CI: [0.021, 0.058]\n",
      "     Error | singleton:       16 /  421  =  3.80%   95% CI: [0.022, 0.061]\n",
      "     Doublets:                 0 /  440  =  0.00%   95% CI: [0.000, 0.008]\n",
      "\n",
      "  Operational bounds for deployment\n",
      "     Method: leave-one-out calibration at confidence 1-δ, plus binomial predictive bounds for sampling variability.\n",
      "     Threshold calibration level: 90% (1-δ)\n",
      "     Reported confidence level for bounds: 95%\n",
      "     Grid points evaluated: 1\n",
      "\n",
      "     Singleton rate\n",
      "       Point estimate: 0.780\n",
      "       Candidate bounds (95% predictive, n_test = 440):\n",
      "         Normal approximation      [0.725, 0.835]   width 0.110  \n",
      "         Exact binomial predictive [0.682, 0.861]   width 0.180  (retained)\n",
      "         Hoeffding                 [0.638, 0.921]   width 0.283  \n",
      "       Operational bounds: [0.682, 0.861]\n",
      "\n",
      "     Doublet rate\n",
      "       Point estimate: 0.220\n",
      "       Candidate bounds (95% predictive, n_test = 440):\n",
      "         Normal approximation      [0.165, 0.275]   width 0.110  \n",
      "         Exact binomial predictive [0.139, 0.318]   width 0.180  (retained)\n",
      "         Hoeffding                 [0.079, 0.362]   width 0.283  \n",
      "       Operational bounds: [0.139, 0.318]\n",
      "\n",
      "     Abstention rate\n",
      "       Point estimate: 0.000\n",
      "       Candidate bounds (95% predictive, n_test = 440):\n",
      "         Normal approximation      [0.000, 0.000]   width 0.000  (retained)\n",
      "         Exact binomial predictive [0.000, 0.036]   width 0.036  (retained)\n",
      "         Hoeffding                 [0.000, 0.170]   width 0.170  \n",
      "       Operational bounds: [0.000, 0.036]\n",
      "\n",
      "     Conditional error rate given singleton (P(error | singleton, class = 0))\n",
      "       Point estimate: 0.102\n",
      "       Candidate bounds (95% predictive, n_test = 440):\n",
      "         Normal approximation      [0.056, 0.148]   width 0.091  \n",
      "         Exact binomial predictive [0.041, 0.190]   width 0.149  (retained)\n",
      "         Hoeffding                 [0.000, 0.262]   width 0.262  \n",
      "       Operational bounds: [0.041, 0.190]\n",
      "\n",
      "     Conditional correct rate given singleton (P(correct | singleton, class = 0))\n",
      "       Point estimate: 0.898\n",
      "       Candidate bounds (95% predictive, n_test = 440):\n",
      "         Normal approximation      [0.056, 0.148]   width 0.091  \n",
      "         Exact binomial predictive [0.041, 0.190]   width 0.149  (retained)\n",
      "         Hoeffding                 [0.000, 0.262]   width 0.262  \n",
      "       Operational bounds: [0.810, 0.959]\n",
      "\n",
      "     Stability note:\n",
      "        All rates above (singleton, doublet, abstention, conditional error) are conditional on class 0.\n",
      "        Their denominators (number of class 0 samples in the test set) are random at deployment time.\n",
      "        This induces extra variance and can bias the reported intervals.\n",
      "        For audit and Service Level Objective reporting, use the marginal rates\n",
      "        in the next section (normalized by total volume), which have a fixed denominator.\n",
      "\n",
      "================================================================================\n",
      "CLASS 1 (Conditioned on True Label = 1)\n",
      "================================================================================\n",
      "  Calibration size: n = 60\n",
      "  Target miscoverage: α = 0.100\n",
      "  SSBC-corrected α:   α' = 0.0492\n",
      "  PAC risk:           δ = 0.100\n",
      "  Conformal threshold: 0.7123\n",
      "\n",
      "  Calibration summary (n = 60)\n",
      "     Empirical rates on calibration data. Intervals are 95% Clopper-Pearson.\n",
      "     These do not include PAC guarantees.\n",
      "     Abstentions:               0 /   60  =  0.00%   95% CI: [0.000, 0.060]\n",
      "     Singletons:             23 /   60  = 38.33%   95% CI: [0.261, 0.518]\n",
      "       Correct:              21 /   60  = 35.00%   95% CI: [0.231, 0.484]\n",
      "       Incorrect:              2 /   60  =  3.33%   95% CI: [0.004, 0.115]\n",
      "     Error | singleton:        2 /   23  =  8.70%   95% CI: [0.011, 0.280]\n",
      "     Doublets:                37 /   60  = 61.67%   95% CI: [0.482, 0.739]\n",
      "\n",
      "  Operational bounds for deployment\n",
      "     Method: leave-one-out calibration at confidence 1-δ, plus binomial predictive bounds for sampling variability.\n",
      "     Threshold calibration level: 90% (1-δ)\n",
      "     Reported confidence level for bounds: 95%\n",
      "     Grid points evaluated: 1\n",
      "\n",
      "     Singleton rate\n",
      "       Point estimate: 0.883\n",
      "       Candidate bounds (95% predictive, n_test = 60):\n",
      "         Normal approximation      [0.765, 1.000]   width 0.235  \n",
      "         Exact binomial predictive [0.617, 1.000]   width 0.383  (retained)\n",
      "         Hoeffding                 [0.498, 1.000]   width 0.502  \n",
      "       Operational bounds: [0.617, 1.000]\n",
      "\n",
      "     Doublet rate\n",
      "       Point estimate: 0.117\n",
      "       Candidate bounds (95% predictive, n_test = 60):\n",
      "         Normal approximation      [0.000, 0.235]   width 0.235  \n",
      "         Exact binomial predictive [0.000, 0.383]   width 0.383  (retained)\n",
      "         Hoeffding                 [0.000, 0.502]   width 0.502  \n",
      "       Operational bounds: [0.000, 0.383]\n",
      "\n",
      "     Abstention rate\n",
      "       Point estimate: 0.000\n",
      "       Candidate bounds (95% predictive, n_test = 60):\n",
      "         Normal approximation      [0.000, 0.000]   width 0.000  (retained)\n",
      "         Exact binomial predictive [0.000, 0.250]   width 0.250  (retained)\n",
      "         Hoeffding                 [0.000, 0.461]   width 0.461  \n",
      "       Operational bounds: [0.000, 0.250]\n",
      "\n",
      "     Conditional error rate given singleton (P(error | singleton, class = 1))\n",
      "       Point estimate: 0.038\n",
      "       Candidate bounds (95% predictive, n_test = 60):\n",
      "         Normal approximation      [0.000, 0.113]   width 0.113  \n",
      "         Exact binomial predictive [0.000, 0.264]   width 0.264  (retained)\n",
      "         Hoeffding                 [0.000, 0.448]   width 0.448  \n",
      "       Operational bounds: [0.000, 0.264]\n",
      "\n",
      "     Conditional correct rate given singleton (P(correct | singleton, class = 1))\n",
      "       Point estimate: 0.962\n",
      "       Candidate bounds (95% predictive, n_test = 60):\n",
      "         Normal approximation      [0.000, 0.113]   width 0.113  \n",
      "         Exact binomial predictive [0.000, 0.264]   width 0.264  (retained)\n",
      "         Hoeffding                 [0.000, 0.448]   width 0.448  \n",
      "       Operational bounds: [0.736, 1.000]\n",
      "\n",
      "     Stability note:\n",
      "        All rates above (singleton, doublet, abstention, conditional error) are conditional on class 1.\n",
      "        Their denominators (number of class 1 samples in the test set) are random at deployment time.\n",
      "        This induces extra variance and can bias the reported intervals.\n",
      "        For audit and Service Level Objective reporting, use the marginal rates\n",
      "        in the next section (normalized by total volume), which have a fixed denominator.\n",
      "\n",
      "================================================================================\n",
      "MARGINAL STATISTICS (deployment view; class labels not assumed known)\n",
      "================================================================================\n",
      "  Total samples: n = 500\n",
      "\n",
      "  Calibration summary (n = 500)\n",
      "     Empirical rates on calibration data. Intervals are 95% Clopper-Pearson.\n",
      "     No PAC guarantees.\n",
      "     Coverage (prediction set contains true label):  463 /  500  = 92.60%   95% CI: [0.899, 0.947]\n",
      "     Abstentions:               0 /  500  =  0.00%   95% CI: [0.000, 0.007]\n",
      "     Singletons:            396 /  500  = 79.20%   95% CI: [0.754, 0.827]\n",
      "       Errors:               37 /  396  =  9.34%   95% CI: [0.067, 0.126]\n",
      "     Doublets:               104 /  500  = 20.80%   95% CI: [0.173, 0.246]\n",
      "\n",
      "  Operational bounds for deployment\n",
      "     Class-specific rates (normalized by total test set size):\n",
      "     - Singleton, doublet, and abstention rates for class 0 and class 1 (fixed denominator)\n",
      "     - Error rates for class 0 and class 1 singletons (fixed denominator)\n",
      "     Reported confidence level for bounds: 95%\n",
      "\n",
      "     Singleton rate (Class 0, normalized by total)\n",
      "       Point estimate: 0.686\n",
      "       Candidate bounds (95% predictive, n_test = 500):\n",
      "         Normal approximation      [0.628, 0.744]   width 0.116  \n",
      "         Exact binomial predictive [0.590, 0.776]   width 0.186  (retained)\n",
      "         Hoeffding                 [0.553, 0.819]   width 0.265  \n",
      "       Operational bounds: [0.590, 0.776]\n",
      "\n",
      "     Singleton rate (Class 1, normalized by total)\n",
      "       Point estimate: 0.106\n",
      "       Candidate bounds (95% predictive, n_test = 500):\n",
      "         Normal approximation      [0.068, 0.144]   width 0.077  \n",
      "         Exact binomial predictive [0.052, 0.178]   width 0.126  (retained)\n",
      "         Hoeffding                 [0.000, 0.239]   width 0.239  \n",
      "       Operational bounds: [0.052, 0.178]\n",
      "\n",
      "     Doublet rate (Class 0, normalized by total)\n",
      "       Point estimate: 0.194\n",
      "       Candidate bounds (95% predictive, n_test = 500):\n",
      "         Normal approximation      [0.145, 0.243]   width 0.098  \n",
      "         Exact binomial predictive [0.120, 0.282]   width 0.162  (retained)\n",
      "         Hoeffding                 [0.061, 0.327]   width 0.265  \n",
      "       Operational bounds: [0.120, 0.282]\n",
      "\n",
      "     Doublet rate (Class 1, normalized by total)\n",
      "       Point estimate: 0.014\n",
      "       Candidate bounds (95% predictive, n_test = 500):\n",
      "         Normal approximation      [0.000, 0.029]   width 0.029  \n",
      "         Exact binomial predictive [0.000, 0.050]   width 0.050  (retained)\n",
      "         Hoeffding                 [0.000, 0.147]   width 0.147  \n",
      "       Operational bounds: [0.000, 0.050]\n",
      "\n",
      "     Abstention rate (Class 0, normalized by total)\n",
      "       Point estimate: 0.000\n",
      "       Candidate bounds (95% predictive, n_test = 500):\n",
      "         Normal approximation      [0.000, 0.000]   width 0.000  (retained)\n",
      "         Exact binomial predictive [0.000, 0.032]   width 0.032  (retained)\n",
      "         Hoeffding                 [0.000, 0.160]   width 0.160  \n",
      "       Operational bounds: [0.000, 0.032]\n",
      "\n",
      "     Abstention rate (Class 1, normalized by total)\n",
      "       Point estimate: 0.000\n",
      "       Candidate bounds (95% predictive, n_test = 500):\n",
      "         Normal approximation      [0.000, 0.000]   width 0.000  (retained)\n",
      "         Exact binomial predictive [0.000, 0.032]   width 0.032  (retained)\n",
      "         Hoeffding                 [0.000, 0.160]   width 0.160  \n",
      "       Operational bounds: [0.000, 0.032]\n",
      "\n",
      "     Error rate (Class 0 singletons, normalized by total)\n",
      "       Point estimate: 0.070\n",
      "       Candidate bounds (95% predictive, n_test = 500):\n",
      "         Normal approximation      [0.038, 0.102]   width 0.064  \n",
      "         Exact binomial predictive [0.028, 0.132]   width 0.104  (retained)\n",
      "         Hoeffding                 [0.000, 0.203]   width 0.203  \n",
      "       Operational bounds: [0.028, 0.132]\n",
      "\n",
      "     Error rate (Class 1 singletons, normalized by total)\n",
      "       Point estimate: 0.004\n",
      "       Candidate bounds (95% predictive, n_test = 500):\n",
      "         Normal approximation      [0.000, 0.012]   width 0.012  \n",
      "         Exact binomial predictive [0.000, 0.030]   width 0.030  (retained)\n",
      "         Hoeffding                 [0.000, 0.137]   width 0.137  \n",
      "       Operational bounds: [0.000, 0.030]\n",
      "\n",
      "     Correct rate (Class 0 singletons, normalized by total)\n",
      "       Point estimate: 0.616\n",
      "       Candidate bounds (95% predictive, n_test = 500):\n",
      "         Normal approximation      [0.555, 0.677]   width 0.121  \n",
      "         Exact binomial predictive [0.516, 0.712]   width 0.196  (retained)\n",
      "         Hoeffding                 [0.483, 0.749]   width 0.265  \n",
      "       Operational bounds: [0.516, 0.712]\n",
      "\n",
      "     Correct rate (Class 1 singletons, normalized by total)\n",
      "       Point estimate: 0.102\n",
      "       Candidate bounds (95% predictive, n_test = 500):\n",
      "         Normal approximation      [0.064, 0.140]   width 0.075  \n",
      "         Exact binomial predictive [0.050, 0.172]   width 0.122  (retained)\n",
      "         Hoeffding                 [0.000, 0.235]   width 0.235  \n",
      "       Operational bounds: [0.050, 0.172]\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "report = generate_rigorous_pac_report(\n",
    "    labels=labels,\n",
    "    probs=probs,\n",
    "    alpha_target=0.10,\n",
    "    delta=0.10,\n",
    "    test_size=N_samples,\n",
    "    ci_level=0.95,\n",
    "    use_union_bound=False,\n",
    "    prediction_method=\"all\",\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    "    loo_inflation_factor=None,\n",
    "    use_loo_correction=True\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f939516-0fe4-4f5b-ab29-f3a2d50db91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.86281101 0.13718899]\n",
      " [0.88025134 0.11974866]\n",
      " [0.69948143 0.30051857]\n",
      " [0.75583485 0.24416515]\n",
      " [0.55405886 0.44594114]\n",
      " [0.79399193 0.20600807]\n",
      " [0.60406963 0.39593037]\n",
      " [0.85094274 0.14905726]\n",
      " [0.80011812 0.19988188]\n",
      " [0.94020008 0.05979992]\n",
      " [0.9009896  0.0990104 ]\n",
      " [0.77303383 0.22696617]\n",
      " [0.86740762 0.13259238]\n",
      " [0.88327446 0.11672554]\n",
      " [0.61103335 0.38896665]\n",
      " [0.65570958 0.34429042]\n",
      " [0.6304403  0.3695597 ]\n",
      " [0.62302763 0.37697237]\n",
      " [0.93705195 0.06294805]\n",
      " [0.94908903 0.05091097]\n",
      " [0.52553597 0.47446403]\n",
      " [0.72190574 0.27809426]\n",
      " [0.75096114 0.24903886]\n",
      " [0.87032394 0.12967606]\n",
      " [0.86021085 0.13978915]\n",
      " [0.7355327  0.2644673 ]\n",
      " [0.81645998 0.18354002]\n",
      " [0.76952874 0.23047126]\n",
      " [0.89563947 0.10436053]\n",
      " [0.86034029 0.13965971]\n",
      " [0.73324496 0.26675504]\n",
      " [0.6579529  0.3420471 ]\n",
      " [0.6904643  0.3095357 ]\n",
      " [0.48104307 0.51895693]\n",
      " [0.65668747 0.34331253]\n",
      " [0.91575015 0.08424985]\n",
      " [0.47664347 0.52335653]\n",
      " [0.76660722 0.23339278]\n",
      " [0.96246112 0.03753888]\n",
      " [0.78674116 0.21325884]\n",
      " [0.57344311 0.42655689]\n",
      " [0.80848275 0.19151725]\n",
      " [0.9585675  0.0414325 ]\n",
      " [0.77691378 0.22308622]\n",
      " [0.6147177  0.3852823 ]\n",
      " [0.9380071  0.0619929 ]\n",
      " [0.3751668  0.6248332 ]\n",
      " [0.85126308 0.14873692]\n",
      " [0.80627663 0.19372337]\n",
      " [0.6971482  0.3028518 ]\n",
      " [0.67352116 0.32647884]\n",
      " [0.92306179 0.07693821]\n",
      " [0.58985406 0.41014594]\n",
      " [0.9199386  0.0800614 ]\n",
      " [0.81208025 0.18791975]\n",
      " [0.42264755 0.57735245]\n",
      " [0.82679401 0.17320599]\n",
      " [0.77668307 0.22331693]\n",
      " [0.92985887 0.07014113]\n",
      " [0.87884389 0.12115611]\n",
      " [0.49382014 0.50617986]\n",
      " [0.81170628 0.18829372]\n",
      " [0.65032855 0.34967145]\n",
      " [0.72921919 0.27078081]\n",
      " [0.85786169 0.14213831]\n",
      " [0.60085678 0.39914322]\n",
      " [0.86538719 0.13461281]\n",
      " [0.76960493 0.23039507]\n",
      " [0.95543859 0.04456141]\n",
      " [0.76304274 0.23695726]\n",
      " [0.74046214 0.25953786]\n",
      " [0.80409126 0.19590874]\n",
      " [0.68300175 0.31699825]\n",
      " [0.83095232 0.16904768]\n",
      " [0.65448845 0.34551155]\n",
      " [0.26385107 0.73614893]\n",
      " [0.76541122 0.23458878]\n",
      " [0.79930172 0.20069828]\n",
      " [0.93328174 0.06671826]\n",
      " [0.84295237 0.15704763]\n",
      " [0.72096308 0.27903692]\n",
      " [0.55604911 0.44395089]\n",
      " [0.835971   0.164029  ]\n",
      " [0.85301793 0.14698207]\n",
      " [0.70652493 0.29347507]\n",
      " [0.68962681 0.31037319]\n",
      " [0.8576223  0.1423777 ]\n",
      " [0.71821316 0.28178684]\n",
      " [0.63516456 0.36483544]\n",
      " [0.66447632 0.33552368]\n",
      " [0.87111965 0.12888035]\n",
      " [0.89469742 0.10530258]\n",
      " [0.90276882 0.09723118]\n",
      " [0.69245606 0.30754394]\n",
      " [0.81772586 0.18227414]\n",
      " [0.87395827 0.12604173]\n",
      " [0.80240966 0.19759034]\n",
      " [0.8343226  0.1656774 ]\n",
      " [0.78019315 0.21980685]\n",
      " [0.9299045  0.0700955 ]\n",
      " [0.77472036 0.22527964]\n",
      " [0.92159    0.07841   ]\n",
      " [0.85143045 0.14856955]\n",
      " [0.81634421 0.18365579]\n",
      " [0.66952163 0.33047837]\n",
      " [0.67204536 0.32795464]\n",
      " [0.83420452 0.16579548]\n",
      " [0.44454665 0.55545335]\n",
      " [0.86103197 0.13896803]\n",
      " [0.90946143 0.09053857]\n",
      " [0.56790696 0.43209304]\n",
      " [0.7904539  0.2095461 ]\n",
      " [0.79548476 0.20451524]\n",
      " [0.78260646 0.21739354]\n",
      " [0.85029827 0.14970173]\n",
      " [0.85600054 0.14399946]\n",
      " [0.81917266 0.18082734]\n",
      " [0.84538299 0.15461701]\n",
      " [0.47482848 0.52517152]\n",
      " [0.83138358 0.16861642]\n",
      " [0.93605759 0.06394241]\n",
      " [0.80085222 0.19914778]\n",
      " [0.73943114 0.26056886]\n",
      " [0.80745873 0.19254127]\n",
      " [0.64350914 0.35649086]\n",
      " [0.69198379 0.30801621]\n",
      " [0.71666111 0.28333889]\n",
      " [0.54835752 0.45164248]\n",
      " [0.77312153 0.22687847]\n",
      " [0.72243069 0.27756931]\n",
      " [0.91193979 0.08806021]\n",
      " [0.53842414 0.46157586]\n",
      " [0.73947208 0.26052792]\n",
      " [0.65227734 0.34772266]\n",
      " [0.93672142 0.06327858]\n",
      " [0.58223249 0.41776751]\n",
      " [0.733466   0.266534  ]\n",
      " [0.73054369 0.26945631]\n",
      " [0.87269255 0.12730745]\n",
      " [0.8109576  0.1890424 ]\n",
      " [0.87264524 0.12735476]\n",
      " [0.63257329 0.36742671]\n",
      " [0.77481206 0.22518794]\n",
      " [0.903821   0.096179  ]\n",
      " [0.94169444 0.05830556]\n",
      " [0.84486885 0.15513115]\n",
      " [0.64061712 0.35938288]\n",
      " [0.7733228  0.2266772 ]\n",
      " [0.55548872 0.44451128]\n",
      " [0.96211243 0.03788757]\n",
      " [0.89054408 0.10945592]\n",
      " [0.78189027 0.21810973]\n",
      " [0.81244915 0.18755085]\n",
      " [0.83967194 0.16032806]\n",
      " [0.73464245 0.26535755]\n",
      " [0.94000145 0.05999855]\n",
      " [0.80725101 0.19274899]\n",
      " [0.97301044 0.02698956]\n",
      " [0.77767627 0.22232373]\n",
      " [0.86590171 0.13409829]\n",
      " [0.89366074 0.10633926]\n",
      " [0.98152204 0.01847796]\n",
      " [0.86608416 0.13391584]\n",
      " [0.77330833 0.22669167]\n",
      " [0.91742457 0.08257543]\n",
      " [0.71644101 0.28355899]\n",
      " [0.96947723 0.03052277]\n",
      " [0.83742802 0.16257198]\n",
      " [0.84726642 0.15273358]\n",
      " [0.67133184 0.32866816]\n",
      " [0.9810528  0.0189472 ]\n",
      " [0.81043885 0.18956115]\n",
      " [0.81104469 0.18895531]\n",
      " [0.89311037 0.10688963]\n",
      " [0.85469912 0.14530088]\n",
      " [0.65989424 0.34010576]\n",
      " [0.80710153 0.19289847]\n",
      " [0.47031473 0.52968527]\n",
      " [0.81818451 0.18181549]\n",
      " [0.68386011 0.31613989]\n",
      " [0.87365076 0.12634924]\n",
      " [0.71840502 0.28159498]\n",
      " [0.88399127 0.11600873]\n",
      " [0.86829456 0.13170544]\n",
      " [0.81058771 0.18941229]\n",
      " [0.80766135 0.19233865]\n",
      " [0.78539815 0.21460185]\n",
      " [0.95443611 0.04556389]\n",
      " [0.87320235 0.12679765]\n",
      " [0.69887961 0.30112039]\n",
      " [0.6062735  0.3937265 ]\n",
      " [0.98362349 0.01637651]\n",
      " [0.87781022 0.12218978]\n",
      " [0.79868529 0.20131471]\n",
      " [0.83290871 0.16709129]\n",
      " [0.83457431 0.16542569]\n",
      " [0.92199669 0.07800331]\n",
      " [0.89172567 0.10827433]\n",
      " [0.68509304 0.31490696]\n",
      " [0.37523003 0.62476997]\n",
      " [0.91927559 0.08072441]\n",
      " [0.7038187  0.2961813 ]\n",
      " [0.77275309 0.22724691]\n",
      " [0.95184943 0.04815057]\n",
      " [0.7999031  0.2000969 ]\n",
      " [0.82288935 0.17711065]\n",
      " [0.9182471  0.0817529 ]\n",
      " [0.71369897 0.28630103]\n",
      " [0.7884117  0.2115883 ]\n",
      " [0.69934384 0.30065616]\n",
      " [0.68827475 0.31172525]\n",
      " [0.56467414 0.43532586]\n",
      " [0.8808859  0.1191141 ]\n",
      " [0.79413519 0.20586481]\n",
      " [0.8136765  0.1863235 ]\n",
      " [0.79710183 0.20289817]\n",
      " [0.82582583 0.17417417]\n",
      " [0.95066239 0.04933761]\n",
      " [0.59142212 0.40857788]\n",
      " [0.73781765 0.26218235]\n",
      " [0.84553665 0.15446335]\n",
      " [0.76640242 0.23359758]\n",
      " [0.56552962 0.43447038]\n",
      " [0.8769514  0.1230486 ]\n",
      " [0.76404188 0.23595812]\n",
      " [0.70517132 0.29482868]\n",
      " [0.72164529 0.27835471]\n",
      " [0.553495   0.446505  ]\n",
      " [0.80054659 0.19945341]\n",
      " [0.42746682 0.57253318]\n",
      " [0.45843588 0.54156412]\n",
      " [0.72842529 0.27157471]\n",
      " [0.54476304 0.45523696]\n",
      " [0.62785338 0.37214662]\n",
      " [0.87244053 0.12755947]\n",
      " [0.66140969 0.33859031]\n",
      " [0.79009795 0.20990205]\n",
      " [0.64756084 0.35243916]\n",
      " [0.8860294  0.1139706 ]\n",
      " [0.95223543 0.04776457]\n",
      " [0.49917124 0.50082876]\n",
      " [0.41147064 0.58852936]\n",
      " [0.77845332 0.22154668]\n",
      " [0.86561493 0.13438507]\n",
      " [0.77291704 0.22708296]\n",
      " [0.35111101 0.64888899]\n",
      " [0.50520969 0.49479031]\n",
      " [0.95257883 0.04742117]\n",
      " [0.69072325 0.30927675]\n",
      " [0.60614025 0.39385975]\n",
      " [0.7103041  0.2896959 ]\n",
      " [0.71670326 0.28329674]\n",
      " [0.89425369 0.10574631]\n",
      " [0.76759806 0.23240194]\n",
      " [0.65812652 0.34187348]\n",
      " [0.73770843 0.26229157]\n",
      " [0.90043904 0.09956096]\n",
      " [0.71859734 0.28140266]\n",
      " [0.97243277 0.02756723]\n",
      " [0.27109967 0.72890033]\n",
      " [0.61055429 0.38944571]\n",
      " [0.79869558 0.20130442]\n",
      " [0.72447478 0.27552522]\n",
      " [0.72552347 0.27447653]\n",
      " [0.70902428 0.29097572]\n",
      " [0.88972003 0.11027997]\n",
      " [0.66669841 0.33330159]\n",
      " [0.58141169 0.41858831]\n",
      " [0.77634244 0.22365756]\n",
      " [0.90206457 0.09793543]\n",
      " [0.74644046 0.25355954]\n",
      " [0.86986661 0.13013339]\n",
      " [0.79975744 0.20024256]\n",
      " [0.95624549 0.04375451]\n",
      " [0.88786603 0.11213397]\n",
      " [0.88854179 0.11145821]\n",
      " [0.74960066 0.25039934]\n",
      " [0.82423448 0.17576552]\n",
      " [0.82711724 0.17288276]\n",
      " [0.74330693 0.25669307]\n",
      " [0.77305536 0.22694464]\n",
      " [0.9554602  0.0445398 ]\n",
      " [0.82128668 0.17871332]\n",
      " [0.8472285  0.1527715 ]\n",
      " [0.51664894 0.48335106]\n",
      " [0.39346338 0.60653662]\n",
      " [0.93395838 0.06604162]\n",
      " [0.46712347 0.53287653]\n",
      " [0.80121458 0.19878542]\n",
      " [0.65242057 0.34757943]\n",
      " [0.61863757 0.38136243]\n",
      " [0.43647172 0.56352828]\n",
      " [0.80136406 0.19863594]\n",
      " [0.88639507 0.11360493]\n",
      " [0.75569294 0.24430706]\n",
      " [0.83130889 0.16869111]\n",
      " [0.86450247 0.13549753]\n",
      " [0.59577779 0.40422221]\n",
      " [0.71426086 0.28573914]\n",
      " [0.97394393 0.02605607]\n",
      " [0.72367315 0.27632685]\n",
      " [0.8721505  0.1278495 ]\n",
      " [0.94171595 0.05828405]\n",
      " [0.77397704 0.22602296]\n",
      " [0.87496011 0.12503989]\n",
      " [0.7188366  0.2811634 ]\n",
      " [0.85200174 0.14799826]\n",
      " [0.41283982 0.58716018]\n",
      " [0.88142596 0.11857404]\n",
      " [0.70506732 0.29493268]\n",
      " [0.94858555 0.05141445]\n",
      " [0.84578237 0.15421763]\n",
      " [0.41884154 0.58115846]\n",
      " [0.92581563 0.07418437]\n",
      " [0.812326   0.187674  ]\n",
      " [0.70235197 0.29764803]\n",
      " [0.875393   0.124607  ]\n",
      " [0.80181534 0.19818466]\n",
      " [0.98143343 0.01856657]\n",
      " [0.72722332 0.27277668]\n",
      " [0.70479649 0.29520351]\n",
      " [0.82881709 0.17118291]\n",
      " [0.71858925 0.28141075]\n",
      " [0.80010546 0.19989454]\n",
      " [0.4001101  0.5998899 ]\n",
      " [0.77729092 0.22270908]\n",
      " [0.6555159  0.3444841 ]\n",
      " [0.67476811 0.32523189]\n",
      " [0.63738623 0.36261377]\n",
      " [0.82409958 0.17590042]\n",
      " [0.58787643 0.41212357]\n",
      " [0.73968627 0.26031373]\n",
      " [0.45313628 0.54686372]\n",
      " [0.91543244 0.08456756]\n",
      " [0.75655516 0.24344484]\n",
      " [0.95756062 0.04243938]\n",
      " [0.51408567 0.48591433]\n",
      " [0.87619838 0.12380162]\n",
      " [0.93512643 0.06487357]\n",
      " [0.6265192  0.3734808 ]\n",
      " [0.45461792 0.54538208]\n",
      " [0.87098766 0.12901234]\n",
      " [0.79627477 0.20372523]\n",
      " [0.77029591 0.22970409]\n",
      " [0.77808042 0.22191958]\n",
      " [0.87790812 0.12209188]\n",
      " [0.57510794 0.42489206]\n",
      " [0.7516028  0.2483972 ]\n",
      " [0.98036398 0.01963602]\n",
      " [0.89516289 0.10483711]\n",
      " [0.80377077 0.19622923]\n",
      " [0.80129681 0.19870319]\n",
      " [0.84763076 0.15236924]\n",
      " [0.50959616 0.49040384]\n",
      " [0.89224438 0.10775562]\n",
      " [0.91044919 0.08955081]\n",
      " [0.72998384 0.27001616]\n",
      " [0.56400276 0.43599724]\n",
      " [0.83619446 0.16380554]\n",
      " [0.76456431 0.23543569]\n",
      " [0.67205196 0.32794804]\n",
      " [0.65120857 0.34879143]\n",
      " [0.91415629 0.08584371]\n",
      " [0.87406974 0.12593026]\n",
      " [0.65427653 0.34572347]\n",
      " [0.71115064 0.28884936]\n",
      " [0.81839138 0.18160862]\n",
      " [0.50119034 0.49880966]\n",
      " [0.77690122 0.22309878]\n",
      " [0.58717831 0.41282169]\n",
      " [0.7439632  0.2560368 ]\n",
      " [0.88427404 0.11572596]\n",
      " [0.73654611 0.26345389]\n",
      " [0.9716697  0.0283303 ]\n",
      " [0.62317387 0.37682613]\n",
      " [0.60886383 0.39113617]\n",
      " [0.71379584 0.28620416]\n",
      " [0.83976593 0.16023407]\n",
      " [0.95276499 0.04723501]\n",
      " [0.95354673 0.04645327]\n",
      " [0.93943656 0.06056344]\n",
      " [0.89915826 0.10084174]\n",
      " [0.80964608 0.19035392]\n",
      " [0.66276579 0.33723421]\n",
      " [0.62748059 0.37251941]\n",
      " [0.86430878 0.13569122]\n",
      " [0.82420363 0.17579637]\n",
      " [0.95533395 0.04466605]\n",
      " [0.84319481 0.15680519]\n",
      " [0.60577963 0.39422037]\n",
      " [0.61318472 0.38681528]\n",
      " [0.7681579  0.2318421 ]\n",
      " [0.70661655 0.29338345]\n",
      " [0.92496008 0.07503992]\n",
      " [0.92439793 0.07560207]\n",
      " [0.93726071 0.06273929]\n",
      " [0.74463844 0.25536156]\n",
      " [0.94797002 0.05202998]\n",
      " [0.86574881 0.13425119]\n",
      " [0.8714257  0.1285743 ]\n",
      " [0.90685258 0.09314742]\n",
      " [0.47239863 0.52760137]\n",
      " [0.86817387 0.13182613]\n",
      " [0.55104589 0.44895411]\n",
      " [0.8362862  0.1637138 ]\n",
      " [0.62625384 0.37374616]\n",
      " [0.63466468 0.36533532]\n",
      " [0.69248677 0.30751323]\n",
      " [0.85713713 0.14286287]\n",
      " [0.77230995 0.22769005]\n",
      " [0.76035246 0.23964754]\n",
      " [0.91998849 0.08001151]\n",
      " [0.49718219 0.50281781]\n",
      " [0.95576401 0.04423599]\n",
      " [0.47645429 0.52354571]\n",
      " [0.61928899 0.38071101]\n",
      " [0.98062072 0.01937928]\n",
      " [0.59331687 0.40668313]\n",
      " [0.83561445 0.16438555]\n",
      " [0.92137987 0.07862013]\n",
      " [0.66287826 0.33712174]\n",
      " [0.94220096 0.05779904]\n",
      " [0.82911285 0.17088715]\n",
      " [0.82160521 0.17839479]\n",
      " [0.64868842 0.35131158]\n",
      " [0.61818892 0.38181108]\n",
      " [0.82379405 0.17620595]\n",
      " [0.85038571 0.14961429]\n",
      " [0.7624576  0.2375424 ]\n",
      " [0.82714403 0.17285597]\n",
      " [0.76605577 0.23394423]\n",
      " [0.83693082 0.16306918]\n",
      " [0.53478869 0.46521131]\n",
      " [0.87392923 0.12607077]\n",
      " [0.93082334 0.06917666]\n",
      " [0.67104108 0.32895892]\n",
      " [0.80726267 0.19273733]\n",
      " [0.81036527 0.18963473]\n",
      " [0.76983105 0.23016895]\n",
      " [0.89980103 0.10019897]]\n",
      "0.506179859158635\n",
      "[[ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True  True]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True  True]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "sel0 = labels == 0\n",
    "p0 = probs[sel0]\n",
    "no = len(p0)\n",
    "print(p0)\n",
    "t0 = np.quantile( 1-p0[:,0],  (1-0.05555555555555555), method='higher')\n",
    "print(t0)\n",
    "sets = (1-p0) < t0\n",
    "print(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c7488c-2cee-4ff0-87b7-fcd8a2aec779",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel1 = labels == 1\n",
    "p1 = probs[sel1]\n",
    "plt.hist(p1[:,1], bins=100)\n",
    "plt.show()\n",
    "n1 = len(p1)\n",
    "t1 = np.quantile( 1-p1[:,1],  (1-0.03333333333333333), method='higher')\n",
    "print(t1)\n",
    "sets1 = (1-p1) < t1\n",
    "print(p1)\n",
    "print(sets1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b2a7f6-07b1-438e-895a-6e2420cfab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_0 = report[\"calibration_result\"][0][\"threshold\"]\n",
    "tau_1 = report[\"calibration_result\"][1][\"threshold\"]\n",
    "plt.hist(1-class_data[0][\"probs\"][:, 0], bins=np.linspace(0, 1, 50), alpha=0.75)\n",
    "plt.hist(1-class_data[1][\"probs\"][:, 1], bins=np.linspace(0, 1, 50), alpha=0.75)\n",
    "plt.ylabel(\"Occurance\")\n",
    "plt.xlabel(\"NCS(Class)\")\n",
    "plt.vlines(tau_0, 0, 40,color='navy', ls=\"--\", lw=1)\n",
    "plt.vlines(tau_1, 0, 40,color='orange', ls=\"--\", lw=1)\n",
    "plt.ylim(0,40)\n",
    "plt.legend([ r\"$\\tau_0$\", r\"$\\tau_1$\", \"Class 0\", \"Class 1\"] )\n",
    "plt.savefig(\"tst-2-7_7_2.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be629d45-8218-48ef-b1c8-f0b246959267",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = ssbc.validate_pac_bounds(\n",
    "    report=report,\n",
    "    simulator=sim,\n",
    "    test_size=N_samples,      # Size of each test set\n",
    "    n_trials=100000,       # Number of independent trials (increase for better stats)\n",
    "    seed=42,             # For reproducibility\n",
    "    verbose=True,\n",
    "    n_jobs=-1,           # Use all CPU cores\n",
    ")\n",
    "\n",
    "ssbc.print_validation_results(validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631bd31-4ef2-4861-be9a-d97338d93a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = ssbc.validate_prediction_interval_calibration(\n",
    "    simulator=sim,\n",
    "    n_calibration=N_samples,        # Size of each calibration dataset\n",
    "    BigN=1000,                  # Number of different calibrations to test\n",
    "    n_trials=1000,             # Test sets per calibration\n",
    "    test_size=N_samples,\n",
    "    ci_level=0.95,\n",
    "    prediction_method=\"all\",  # Compare all methods\n",
    "    use_loo_correction=True,\n",
    "    loo_inflation_factor=1.0,\n",
    "    verbose=False,            # Minimal printouts\n",
    "    n_jobs=-1,\n",
    "    seed=0\n",
    ")\n",
    "# Print results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45dd0c6-6fcd-4e9a-bba0-b91421ba5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = ssbc.get_calibration_bounds_dataframe(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e0288-c86b-4920-8885-d4bf2126ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssbc import validate_prediction_interval_calibration, get_calibration_bounds_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569f327-6202-4bd4-ab4e-6f12d9c1b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssbc import (\n",
    "    validate_prediction_interval_calibration,\n",
    "    get_calibration_bounds_dataframe,\n",
    "    plot_calibration_excess,\n",
    ")\n",
    "def plotter(this_df):\n",
    "    # Plot excess for singleton marginal    \n",
    "    \n",
    "    this_df_m_single = this_df[(this_df['scope'] == 'marginal') & (this_df['metric'] == 'singleton_rate_class0')]\n",
    "    plot_calibration_excess(this_df_m_single, scope='marginal', metric='singleton_rate_class0', methods=['analytical', 'exact', 'hoeffding'])\n",
    "    \n",
    "    this_df_m_single = this_df[(this_df['scope'] == 'marginal') & (this_df['metric'] == 'singleton_rate_class1')]\n",
    "    plot_calibration_excess(this_df_m_single, scope='marginal', metric='singleton_rate_class1', methods=['analytical', 'exact', 'hoeffding'])\n",
    "    \n",
    "    this_df_m_single_e = this_df[(this_df['scope'] == 'marginal') & (this_df['metric'] == 'singleton_error_class0')]\n",
    "    plot_calibration_excess(this_df_m_single_e, scope='marginal', metric='singleton_error_class0', methods=['analytical', 'exact', 'hoeffding'])\n",
    "    \n",
    "    this_df_m_single_e = this_df[(this_df['scope'] == 'marginal') & (this_df['metric'] == 'singleton_error_class1')]\n",
    "    plot_calibration_excess(this_df_m_single_e, scope='marginal', metric='singleton_error_class1', methods=['analytical', 'exact', 'hoeffding'])\n",
    "\n",
    "    this_df_m_doublet = this_df[(this_df['scope'] == 'marginal') & (this_df['metric'] == 'doublet_rate_class0')]\n",
    "    plot_calibration_excess(this_df_m_doublet, scope='marginal', metric='doublet_rate_class0', methods=['analytical', 'exact', 'hoeffding'])\n",
    "    \n",
    "    this_df_m_abstention = this_df[(this_df['scope'] == 'marginal') & (this_df['metric'] == 'doublet_rate_class1')]\n",
    "    plot_calibration_excess(this_df_m_abstention, scope='marginal', metric='doublet_rate_class1', methods=['analytical', 'exact', 'hoeffding'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df129735-8dc0-4715-9cf7-342739f1cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79924038-7677-4153-bff2-2ca0a6436a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssbc.print_calibration_validation_results(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a6c06-184d-482a-983c-00acdbc24165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
